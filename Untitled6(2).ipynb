{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1eb6e37-f180-4f2c-b1af-2201135c6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "056b8e26-da84-4d8b-9f57-3414c54b80da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sender  \\\n",
      "0                   Young Esposito <Young@iworld.de>   \n",
      "1                       Mok <ipline's1983@icable.ph>   \n",
      "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "3                 Michael Parker <ivqrnai@pobox.com>   \n",
      "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
      "\n",
      "                                         receiver  \\\n",
      "0                     user4@gvc.ceas-challenge.cc   \n",
      "1                   user2.2@gvc.ceas-challenge.cc   \n",
      "2                   user2.9@gvc.ceas-challenge.cc   \n",
      "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
      "4                   user2.2@gvc.ceas-challenge.cc   \n",
      "\n",
      "                              date  \\\n",
      "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
      "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
      "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
      "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
      "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
      "\n",
      "                                             subject  \\\n",
      "0                          Never agree to be a loser   \n",
      "1                             Befriend Jenna Jameson   \n",
      "2                               CNN.com Daily Top 10   \n",
      "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4                         SpecialPricesPharmMoreinfo   \n",
      "\n",
      "                                                body  label  urls  \n",
      "0  Buck up, your troubles caused by small dimensi...      1     1  \n",
      "1  \\nUpgrade your sex and pleasures with these te...      1     1  \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1     1  \n",
      "3  Would anyone object to removing .so from this ...      0     1  \n",
      "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1     1  \n"
     ]
    }
   ],
   "source": [
    "# Load CEAS_08 dataset CSV\n",
    "df = pd.read_csv('C:/Users/D.Sathiya Pandi/Downloads/CEAS_08.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99b75d1f-ff20-48e6-bc2b-45c7ffea9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates & missing values in key columns (body and label)\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=['body', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affd93e-cee0-449a-bb35-c708e4909ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.lower().strip()\n",
    "    return ''\n",
    "\n",
    "df['body_clean'] = df['body'].apply(clean_text)\n",
    "\n",
    "# Label encoding\n",
    "label_mapping = {'0': 0, 'legitimate': 0, 'ham': 0,\n",
    "                 '1': 1, 'spam': 1,\n",
    "                 '2': 2, 'phishing': 2}\n",
    "df['label'] = df['label'].astype(str).str.strip().str.lower().map(label_mapping)\n",
    "df = df.dropna(subset=['label'])\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Custom feature extractor class\n",
    "class AdditionalFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        spam_keywords = ['congratulations', 'winner', 'prize', 'urgent', 'bank', 'claim', 'lottery']\n",
    "        suspicious_domains = ['.ru', 'xn--', '.xyz', '.top', '.biz', '.info']\n",
    "        features = []\n",
    "\n",
    "        for text in X:\n",
    "            text_lower = text.lower()\n",
    "            spam_word_count = sum(text_lower.count(word) for word in spam_keywords)\n",
    "            url_count = len(re.findall(r\"http[s]?://\", text_lower))\n",
    "            suspicious_domain_flag = int(any(domain in text_lower for domain in suspicious_domains))\n",
    "            features.append([spam_word_count, url_count, suspicious_domain_flag])\n",
    "\n",
    "        return csr_matrix(features)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=10000, ngram_range=(1, 2), max_df=0.9, min_df=5)\n",
    "X_tfidf = tfidf.fit_transform(df['body_clean'])\n",
    "\n",
    "# Additional features extraction\n",
    "add_features_extractor = AdditionalFeaturesExtractor()\n",
    "X_add_features = add_features_extractor.transform(df['body_clean'])\n",
    "\n",
    "# Combine features\n",
    "X_combined = hstack([X_tfidf, X_add_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be089be3-ace0-46ed-b01a-d1e5799fea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Train model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save model and vectorizers\n",
    "joblib.dump(model, 'model_ceas08_enhanced.pkl')\n",
    "joblib.dump(tfidf, 'vectorizer_ceas08.pkl')\n",
    "joblib.dump(add_features_extractor, 'additional_features_extractor.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f43be-198d-44ba-99e6-8cf16f59e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score : {f1_score(y_test, y_pred, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b70b416-8db9-4471-8ae1-b0db98f2326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing email.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile email.py\n",
    "import streamlit as st\n",
    "import joblib\n",
    "\n",
    "# Load CEAS_08-trained model & vectorizer\n",
    "model = joblib.load('model_ceas08.pkl')\n",
    "vectorizer = joblib.load('vectorizer_ceas08.pkl')\n",
    "\n",
    "label_map = {0: \"Legitimate\", 1: \"Spam\", 2: \"Phishing\"}\n",
    "\n",
    "st.title(\"ðŸ“§ CEAS_08 Email Spam & Phishing Detector\")\n",
    "\n",
    "email_text = st.text_area(\"Paste your email content here:\")\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    if not email_text.strip():\n",
    "        st.warning(\"Please enter email content to predict.\")\n",
    "    else:\n",
    "        # Preprocess & vectorize input\n",
    "        X_input = vectorizer.transform([email_text.lower().strip()])\n",
    "\n",
    "        # Predict with the loaded model\n",
    "        pred = model.predict(X_input)[0]\n",
    "\n",
    "        # Display result\n",
    "        st.success(f\"Prediction: {label_map[pred]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546578f-ce05-420e-8405-4506d5a8ab76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
