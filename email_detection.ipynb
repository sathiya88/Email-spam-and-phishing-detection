{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8822d8-85c2-493f-9537-48af2abf526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a6cb70-bc1b-4c7a-8e85-8ef3f6d4b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sender  \\\n",
      "0                   Young Esposito <Young@iworld.de>   \n",
      "1                       Mok <ipline's1983@icable.ph>   \n",
      "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "3                 Michael Parker <ivqrnai@pobox.com>   \n",
      "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
      "\n",
      "                                         receiver  \\\n",
      "0                     user4@gvc.ceas-challenge.cc   \n",
      "1                   user2.2@gvc.ceas-challenge.cc   \n",
      "2                   user2.9@gvc.ceas-challenge.cc   \n",
      "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
      "4                   user2.2@gvc.ceas-challenge.cc   \n",
      "\n",
      "                              date  \\\n",
      "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
      "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
      "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
      "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
      "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
      "\n",
      "                                             subject  \\\n",
      "0                          Never agree to be a loser   \n",
      "1                             Befriend Jenna Jameson   \n",
      "2                               CNN.com Daily Top 10   \n",
      "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4                         SpecialPricesPharmMoreinfo   \n",
      "\n",
      "                                                body  label  urls  \n",
      "0  Buck up, your troubles caused by small dimensi...      1     1  \n",
      "1  \\nUpgrade your sex and pleasures with these te...      1     1  \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1     1  \n",
      "3  Would anyone object to removing .so from this ...      0     1  \n",
      "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1     1  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('C:/Users/D.Sathiya Pandi/Downloads/CEAS_08.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14db15d-b384-48e9-842c-8b24867a9dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique encoded labels: [1 0]\n",
      "Any NaN in y? False\n"
     ]
    }
   ],
   "source": [
    "# Basic cleaning\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=['body', 'label'])  # Keep only rows with both text and label\n",
    "\n",
    "# Simple text preprocessing function\n",
    "def clean_text(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "# Apply cleaning to email body\n",
    "df['body_clean'] = df['body'].apply(clean_text)\n",
    "\n",
    "# Vectorization for Naive Bayes (Bag-of-Words)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['body_clean'])\n",
    "\n",
    "# --- Label Encoding ---\n",
    "# 1. Normalize to lowercase strings first\n",
    "df['label'] = df['label'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 2. Mapping that handles text and numeric strings\n",
    "label_mapping = {\n",
    "    '0': 0, 'legitimate': 0, 'ham': 0,\n",
    "    '1': 1, 'spam': 1,\n",
    "    '2': 2, 'phishing': 2\n",
    "}\n",
    "\n",
    "y = df['label'].map(label_mapping)\n",
    "\n",
    "# 3. Drop any unmapped labels\n",
    "mask = ~y.isna()\n",
    "X = X[mask]\n",
    "y = y[mask].astype(int)  # Ensure integer type\n",
    "\n",
    "print(\"Unique encoded labels:\", y.unique())\n",
    "print(\"Any NaN in y?\", y.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db85161-63c3-4bd1-8b08-db9b9a2e50f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model & Vectorizer saved as model.pkl and vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib\n",
    "\n",
    "# Assuming X, y, and vectorizer are already created from preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save both model and vectorizer\n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "print(\"âœ… Model & Vectorizer saved as model.pkl and vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e60a6ec5-4424-4898-be59-eada4dc7b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Evaluation Results:\n",
      "Accuracy : 0.960413740263057\n",
      "Precision: 0.9635261052157661\n",
      "Recall   : 0.960413740263057\n",
      "F1 Score : 0.9605216088741081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"ðŸ“Š Model Evaluation Results:\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86bba32d-245e-4fc6-a169-117b012381d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing detection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile detection.py\n",
    "import streamlit as st\n",
    "import joblib\n",
    "\n",
    "# Load saved model & vectorizer\n",
    "model = joblib.load('model.pkl')\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "label_map = {0: 'Legitimate', 1: 'Spam', 2: 'Phishing'}\n",
    "\n",
    "st.title(\"ðŸ“§ Email Spam & Phishing Detector\")\n",
    "\n",
    "email_text = st.text_area(\"Paste your email content here:\")\n",
    "if st.button(\"Predict\"):\n",
    "    X_input = vectorizer.transform([email_text.lower()])\n",
    "    pred = model.predict(X_input)[0]\n",
    "    st.success(f\"Prediction: {label_map[pred]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847dfe2-0ce1-4e35-b315-86ecaaa31c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
