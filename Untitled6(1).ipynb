{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1eb6e37-f180-4f2c-b1af-2201135c6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "056b8e26-da84-4d8b-9f57-3414c54b80da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              sender  \\\n",
      "0                   Young Esposito <Young@iworld.de>   \n",
      "1                       Mok <ipline's1983@icable.ph>   \n",
      "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "3                 Michael Parker <ivqrnai@pobox.com>   \n",
      "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
      "\n",
      "                                         receiver  \\\n",
      "0                     user4@gvc.ceas-challenge.cc   \n",
      "1                   user2.2@gvc.ceas-challenge.cc   \n",
      "2                   user2.9@gvc.ceas-challenge.cc   \n",
      "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
      "4                   user2.2@gvc.ceas-challenge.cc   \n",
      "\n",
      "                              date  \\\n",
      "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
      "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
      "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
      "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
      "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
      "\n",
      "                                             subject  \\\n",
      "0                          Never agree to be a loser   \n",
      "1                             Befriend Jenna Jameson   \n",
      "2                               CNN.com Daily Top 10   \n",
      "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4                         SpecialPricesPharmMoreinfo   \n",
      "\n",
      "                                                body  label  urls  \n",
      "0  Buck up, your troubles caused by small dimensi...      1     1  \n",
      "1  \\nUpgrade your sex and pleasures with these te...      1     1  \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1     1  \n",
      "3  Would anyone object to removing .so from this ...      0     1  \n",
      "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1     1  \n"
     ]
    }
   ],
   "source": [
    "# Load CEAS_08 dataset CSV\n",
    "df = pd.read_csv('C:/Users/D.Sathiya Pandi/Downloads/CEAS_08.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b75d1f-ff20-48e6-bc2b-45c7ffea9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates & missing values in key columns (body and label)\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=['body', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8affd93e-cee0-449a-bb35-c708e4909ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic text cleaning function (can be enhanced for CEAS_08 specifics)\n",
    "def clean_text(text):\n",
    "    # Lowercase, strip, remove extra spaces, could add URL extraction if needed\n",
    "    return str(text).lower().strip()\n",
    "\n",
    "df['body_clean'] = df['body'].apply(clean_text)\n",
    "\n",
    "# TF-IDF vectorizer with parameters suitable for CEAS_08 text distributions\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    max_features=10000,        # limit features for efficiency\n",
    "    ngram_range=(1, 2),        # consider unigrams and bigrams for better context\n",
    "    max_df=0.9,                # ignore terms in more than 90% documents (common words)\n",
    "    min_df=5                   # ignore very rare terms (appearing < 5 docs)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['body_clean'])\n",
    "\n",
    "# Map dataset labels: CEAS_08 may have '0'/'1'/'2' or text; adjust accordingly\n",
    "label_mapping = {\n",
    "    '0': 0, 'legitimate': 0, 'ham': 0,\n",
    "    '1': 1, 'spam': 1,\n",
    "    '2': 2, 'phishing': 2\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].astype(str).str.strip().str.lower()\n",
    "y = df['label'].map(label_mapping)\n",
    "\n",
    "# Filter out unlabeled or unknown mask\n",
    "mask = ~y.isna()\n",
    "X = X[mask]\n",
    "y = y[mask].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be089be3-ace0-46ed-b01a-d1e5799fea79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CEAS_08 Model and Vectorizer saved!\n"
     ]
    }
   ],
   "source": [
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train the Naive Bayes model (MultinomialNB suited for discrete features)\n",
    "model = MultinomialNB(alpha=1.0)  # smoothing parameter alpha can be tuned\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save model and vectorizer for deployment\n",
    "joblib.dump(model, 'model_ceas08.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer_ceas08.pkl')\n",
    "\n",
    "print(\"âœ… CEAS_08 Model and Vectorizer saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "655f43be-198d-44ba-99e6-8cf16f59e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CEAS_08 Model Evaluation ===\n",
      "Accuracy : 0.9780\n",
      "Precision: 0.9789\n",
      "Recall   : 0.9780\n",
      "F1 Score : 0.9781\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"=== CEAS_08 Model Evaluation ===\")\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score : {f1_score(y_test, y_pred, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70b416-8db9-4471-8ae1-b0db98f2326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .py\n",
    "import streamlit as st\n",
    "import joblib\n",
    "\n",
    "# Load CEAS_08-trained model & vectorizer\n",
    "model = joblib.load('model_ceas08.pkl')\n",
    "vectorizer = joblib.load('vectorizer_ceas08.pkl')\n",
    "\n",
    "label_map = {0: \"Legitimate\", 1: \"Spam\", 2: \"Phishing\"}\n",
    "\n",
    "st.title(\"ðŸ“§ CEAS_08 Email Spam & Phishing Detector\")\n",
    "\n",
    "email_text = st.text_area(\"Paste your email content here:\")\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    if not email_text.strip():\n",
    "        st.warning(\"Please enter email content to predict.\")\n",
    "    else:\n",
    "        # Preprocess & vectorize input\n",
    "        X_input = vectorizer.transform([email_text.lower().strip()])\n",
    "\n",
    "        # Predict with the loaded model\n",
    "        pred = model.predict(X_input)[0]\n",
    "\n",
    "        # Display result\n",
    "        st.success(f\"Prediction: {label_map[pred]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
